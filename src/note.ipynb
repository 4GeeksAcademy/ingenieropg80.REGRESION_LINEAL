{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fe56006",
   "metadata": {},
   "source": [
    "Paso 4: Análisis de correlación\n",
    "Revisa la correlación entre variables numéricas y con la variable objetivo (charges).\n",
    "\n",
    "sacar todos los data set \n",
    "\n",
    "\n",
    "Paso 5: Preparación de datos para regresión\n",
    "Codifica variables categóricas (one-hot encoding).\n",
    "Separa variables predictoras (X) y variable objetivo (y).\n",
    "Divide en conjunto de entrenamiento y prueba.\n",
    "python\n",
    "Copy Code\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# One-hot encoding para variables categóricas\n",
    "data_encoded = pd.get_dummies(total_data, drop_first=True)\n",
    "\n",
    "X = data_encoded.drop('charges', axis=1)\n",
    "y = data_encoded['charges']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "Paso 6: Entrenamiento y optimización de regresión lineal\n",
    "Usa GridSearchCV para optimizar hiperparámetros (aunque regresión lineal simple no tiene muchos, puedes probar regularización con Ridge o Lasso).\n",
    "\n",
    "python\n",
    "Copy Code\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "ridge = Ridge()\n",
    "\n",
    "param_grid = {'alpha': [0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "grid_search = GridSearchCV(ridge, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Mejor alpha:\", grid_search.best_params_)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "print(\"RMSE:\", mean_squared_error(y_test, y_pred, squared=False))\n",
    "print(\"R2:\", r2_score(y_test, y_pred))\n",
    "\n",
    "Paso 7: Interpretación y conclusiones\n",
    "Analiza los coeficientes del modelo para entender la influencia de cada variable.\n",
    "Evalúa el desempeño con métricas (RMSE, R2).\n",
    "Considera posibles mejoras (transformaciones, variables nuevas, modelos más complejos). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38b90c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34fdf79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/4GeeksAcademy/linear-regression-project-tutorial/main/medical_insurance_cost.csv\"\n",
    "total_data = pd.read_csv(url)\n",
    "\n",
    "\n",
    "def process_dataframes_shapes(total_data, charges):\n",
    "\n",
    "    # 1. total_data: dataset original\n",
    "    total_data = total_data.copy()\n",
    "\n",
    "    # 2. total_data_no_outliers: ajustar outliers en variables numéricas (winsorizing)\n",
    "    def adjust_outliers(data):\n",
    "        df_adj = data.copy()\n",
    "        numeric_cols = df_adj.select_dtypes(include=['float64', 'int64']).columns.drop(target)\n",
    "        for col in numeric_cols:\n",
    "            Q1 = df_adj[col].quantile(0.25)\n",
    "            Q3 = df_adj[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_bound = Q1 - 1.5 * IQR\n",
    "            upper_bound = Q3 + 1.5 * IQR\n",
    "            df_adj[col] = np.where(df_adj[col] < lower_bound, lower_bound, df_adj[col])\n",
    "            df_adj[col] = np.where(df_adj[col] > upper_bound, upper_bound, df_adj[col])\n",
    "        return df_adj\n",
    "\n",
    "    total_data_no_outliers = adjust_outliers(total_data)\n",
    "\n",
    "    # 3. total_data_factorized: factorizar variables categóricas en total_data\n",
    "    total_data_factorized = total_data.copy()\n",
    "    cat_cols = total_data_factorized.select_dtypes(include=['object', 'category']).columns\n",
    "    for col in cat_cols:\n",
    "        total_data_factorized[col] = total_data_factorized[col].astype('category').cat.codes\n",
    "\n",
    "    # 4. total_data_no_outliers_factorized: factorizar variables categóricas en total_data_no_outliers\n",
    "    total_data_no_outliers_factorized = total_data_no_outliers.copy()\n",
    "    cat_cols_no_out = total_data_no_outliers_factorized.select_dtypes(include=['object', 'category']).columns\n",
    "    for col in cat_cols_no_out:\n",
    "        total_data_no_outliers_factorized[col] = total_data_no_outliers_factorized[col].astype('category').cat.codes\n",
    "\n",
    "    # Función para escalar (sin escalar la variable target)\n",
    "    def scale_data(data, scaler):\n",
    "        data_scaled = data.copy()\n",
    "        numeric_cols = data_scaled.select_dtypes(include=['float64', 'int64']).columns.drop('target')\n",
    "        data_scaled[numeric_cols] = scaler.fit_transform(data_scaled[numeric_cols])\n",
    "        return data_scaled\n",
    "\n",
    "    # 5. total_data_standard: escalado Standard en total_data_factorized\n",
    "    total_data_standard = scale_data(total_data_factorized, StandardScaler())\n",
    "\n",
    "    # 6. total_data_no_outliers_standard: escalado Standard en total_data_no_outliers_factorized\n",
    "    total_data_no_outliers_standard = scale_data(total_data_no_outliers_factorized, StandardScaler())\n",
    "\n",
    "    # 7. total_data_factorized_standard: igual que total_data_standard (ya factorizado)\n",
    "    total_data_factorized_standard = total_data_standard.copy()\n",
    "\n",
    "    # 8. total_data_no_outliers_factorized_standard: igual que total_data_no_outliers_standard\n",
    "    total_data_no_outliers_factorized_standard = total_data_no_outliers_standard.copy()\n",
    "\n",
    "    # 9. total_data_minmax: escalado MinMax en total_data_factorized\n",
    "    total_data_minmax = scale_data(total_data_factorized, MinMaxScaler())\n",
    "\n",
    "    # 10. total_data_no_outliers_minmax: escalado MinMax en total_data_no_outliers_factorized\n",
    "    total_data_no_outliers_minmax = scale_data(total_data_no_outliers_factorized, MinMaxScaler())\n",
    "\n",
    "    # 11. total_data_factorized_minmax: igual que total_data_minmax\n",
    "    total_data_factorized_minmax = total_data_minmax.copy()\n",
    "\n",
    "    # 12. total_data_no_outliers_factorized_minmax: igual que total_data_no_outliers_minmax\n",
    "    total_data_no_outliers_factorized_minmax = total_data_no_outliers_minmax.copy()\n",
    "\n",
    "    return {\n",
    "        'total_data': total_data.shape,\n",
    "        'total_data_no_outliers': total_data_no_outliers.shape,\n",
    "        'total_data_factorized': total_data_factorized.shape,\n",
    "        'total_data_no_outliers_factorized': total_data_no_outliers_factorized.shape,\n",
    "        'total_data_standard': total_data_standard.shape,\n",
    "        'total_data_no_outliers_standard': total_data_no_outliers_standard.shape,\n",
    "        'total_data_factorized_standard': total_data_factorized_standard.shape,\n",
    "        'total_data_no_outliers_factorized_standard': total_data_no_outliers_factorized_standard.shape,\n",
    "        'total_data_minmax': total_data_minmax.shape,\n",
    "        'total_data_no_outliers_minmax': total_data_no_outliers_minmax.shape,\n",
    "        'total_data_factorized_minmax': total_data_factorized_minmax.shape,\n",
    "        'total_data_no_outliers_factorized_minmax': total_data_no_outliers_factorized_minmax.shape\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb7f1d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_numerical_data(dataframe):\n",
    "    numerical_columns = dataframe.select_dtypes(include=['float64', 'int64']).columns\n",
    "    for column in numerical_columns:\n",
    "        fig, axis = plt.subplots(2, 1, figsize=(8, 4), gridspec_kw={'height_ratios': [6, 1]})\n",
    "        # Calculate mean, median, and standard deviation\n",
    "        mean_val = np.mean(dataframe[column])\n",
    "        median_val = np.median(dataframe[column])\n",
    "        std_dev = np.std(dataframe[column])\n",
    "        # Create a multiple subplots with histograms and box plots\n",
    "        sns.histplot(ax=axis[0], data=dataframe, kde=True, x=column).set(xlabel=None)\n",
    "        axis[0].axvline(mean_val, color='red', linestyle='dashed', linewidth=1, label='Mean')\n",
    "        axis[0].axvline(median_val, color='orange', linestyle='dashed', linewidth=1, label='Median')\n",
    "        axis[0].axvline(mean_val + std_dev, color='green', linestyle='dashed', linewidth=1, label='Standard Deviation')\n",
    "        axis[0].axvline(mean_val - std_dev, color='green', linestyle='dashed', linewidth=1)\n",
    "        sns.boxplot(ax=axis[1], data=dataframe, x=column, width=0.6).set(xlabel=None)\n",
    "        axis[1].axvline(mean_val, color='red', linestyle='dashed', linewidth=1, label='Mean')\n",
    "        axis[1].axvline(median_val, color='orange', linestyle='dashed', linewidth=1, label='Median')\n",
    "        axis[1].axvline(mean_val + std_dev, color='green', linestyle='dashed', linewidth=1)\n",
    "        axis[1].axvline(mean_val - std_dev, color='green', linestyle='dashed', linewidth=1)\n",
    "        axis[0].legend()\n",
    "        fig.suptitle(column)\n",
    "        # Adjust the layout\n",
    "        plt.tight_layout()\n",
    "        # Show the plot\n",
    "        plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
